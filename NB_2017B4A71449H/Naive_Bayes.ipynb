{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Naive_Bayes",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tBY-VEqlfUr"
      },
      "source": [
        "import numpy as np\r\n",
        "from random import randrange\r\n",
        "import re\r\n",
        "from statistics import stdev"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdZ4MeIelaju"
      },
      "source": [
        "filename='Stopwords'\n",
        "\n",
        "def Stopwords(filename):\n",
        "    file1 = open(filename, 'r') \n",
        "    #print(file1)\n",
        "    Lines = file1.read() #List of strings\n",
        "    #print(Lines)  \n",
        "    Stopwords=Lines.split('\\n')\n",
        "    #print(Stopwords)\n",
        "    \n",
        "    return Stopwords\n",
        "\n",
        "#Stopwords(filename)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdVtkFImi53O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb0a0c9-2ac6-4a7d-998e-282c4b77d644"
      },
      "source": [
        "### remove unnecessary functions/code\n",
        "### add laplacian for improvement\n",
        "### preprocessing\n",
        "### load stopwords from somewhere\n",
        "\n",
        "def split_lines(filename):\n",
        "    file1 = open(filename, 'r') \n",
        "    Lines = file1.readlines() #List of strings  \n",
        "    lines_list=[]\n",
        "    # Strips the newline character \n",
        "    for line in Lines: \n",
        "        lst=[]        \n",
        "        lst.append(line.strip().split(\"\\t\")[0])#sentence \n",
        "        lst.append(int(line.strip().split(\"\\t\")[1]))#class label\n",
        "        lines_list.append(lst)\n",
        "        #print(lines_list) #[[sdsad,1], [sasda,0]]\n",
        "    return lines_list\n",
        "\n",
        "def tokenizer(string):\n",
        "\n",
        "    string=re.sub('[^A-Za-z0-9]+', ' ', string) # Removing Special Symbols    \n",
        "    string=string.lower() # Converting the txt to lowercase   \n",
        "    stopWords = set(Stopwords(filename))\n",
        "    string=\" \".join(word for word in string.split() if word not in stopWords) #Removing stop words      \n",
        "    return string.split()\n",
        "\n",
        "def compute_counts(X,Y):\n",
        "    dictionary={}#Empty Dictionary [+ve,-ve]\n",
        "    for i in range(0,len(X)):\n",
        "        for word in X[i]:\n",
        "            if word not in dictionary:\n",
        "                dictionary[word]=[1,1] # laplacian smoothing(Min occurrence is 1)\n",
        "            if Y[i]==0:\n",
        "                dictionary[word][0]+=1\n",
        "            else:\n",
        "                dictionary[word][1]+=1\n",
        "    return dictionary\n",
        "\n",
        "def compute_label_count(dictionary):\n",
        "    total_neg_labels=0#0\n",
        "    total_pos_labels=0#1\n",
        "    for word in dictionary:\n",
        "        total_neg_labels+=dictionary[word][0]\n",
        "        total_pos_labels+=dictionary[word][1]\n",
        "\n",
        "    return total_neg_labels,total_pos_labels\n",
        "\n",
        "def predict(sentence,dictionary,neg_count,pos_count,neg_pro,pos_pro):\n",
        "    #neg_prob=neg_count/(neg_count+pos_count)#Initialise with prior probability P(Y=0)\n",
        "    #pos_prob=pos_count/(neg_count+pos_count)#Initialise with prior probability P(Y=1)\n",
        "    neg_prob=neg_pro\n",
        "    pos_prob=pos_pro\n",
        "    #calcultate -ve probablity (numerator only as denominator is same for both the classes)\n",
        "    if(neg_prob!=0):\n",
        "        for word in sentence:\n",
        "            if word not in dictionary:\n",
        "                pass#need not handle\n",
        "            else:\n",
        "                if neg_prob==None:\n",
        "                    neg_prob=dictionary[word][0]/neg_count #P(xi|Y=0)\n",
        "                else:\n",
        "                    neg_prob*=dictionary[word][0]/neg_count\n",
        "    \n",
        "    #calcultate +ve probablity (numerator only as denominator is same for both the classes)\n",
        "    if(pos_prob!=0):\n",
        "        for word in sentence:\n",
        "            if word not in dictionary:\n",
        "                pass#need not handle out of vocabulary words\n",
        "            else:\n",
        "                if pos_prob==None:\n",
        "                    pos_prob=dictionary[word][1]/pos_count #P(xi|Y=0)\n",
        "                else:\n",
        "                    pos_prob*=dictionary[word][1]/pos_count\n",
        "\n",
        "    #print(\"Positive Prob(numerator):\",pos_prob)\n",
        "    #print(\"Negative Prob(numerator):\",neg_prob)\n",
        "    if neg_prob >= pos_prob:\n",
        "        return 0\n",
        "    else:        \n",
        "        return 1\n",
        "\n",
        "# Split a dataset into k folds\n",
        "def cross_validation_split(X,Y, n_folds):\n",
        "    X_split = list()\n",
        "    Y_split = list()\n",
        "    dataset_copy_X = list(X)\n",
        "    dataset_copy_Y = list(Y)\n",
        "    fold_size = int(len(X) / n_folds)\n",
        "    for i in range(n_folds):\n",
        "        fold_X = list()\n",
        "        fold_Y = list()\n",
        "        while len(fold_X) < fold_size:\n",
        "            index = randrange(len(dataset_copy_X))\n",
        "            #print(index)\n",
        "            fold_X.append(dataset_copy_X.pop(index))\n",
        "            fold_Y.append(dataset_copy_Y.pop(index))\n",
        "        X_split.append(fold_X)\n",
        "        Y_split.append(fold_Y)\n",
        "    return X_split,Y_split\n",
        "\n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "    correct = 0\n",
        "    for i in range(len(actual)):\n",
        "        if actual[i] == predicted[i]:\n",
        "            correct += 1\n",
        "    return correct / float(len(actual)) * 100.0\n",
        "\n",
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(X,Y, algorithm, n_folds):\n",
        "    X_folds,Y_folds = cross_validation_split(X,Y, n_folds)\n",
        "    accuracies = list()\n",
        "\n",
        "    for (fold_X,fold_Y) in zip(X_folds,Y_folds):\n",
        "        train_set_X = list(X_folds)\n",
        "        train_set_Y = list(Y_folds)\n",
        "        train_set_X.remove(fold_X)\n",
        "        train_set_Y.remove(fold_Y)\n",
        "        train_set_X = sum(train_set_X, [])\n",
        "        train_set_Y = sum(train_set_Y, [])\n",
        "        test_set_X = list()\n",
        "        test_set_Y = list()\n",
        "        for (row_X,row_Y) in zip(fold_X,fold_Y):\n",
        "            row_copy_X = list(row_X) \n",
        "            row_copy_Y = row_Y\n",
        "            test_set_X.append(row_copy_X)\n",
        "            test_set_Y.append(row_copy_Y)\n",
        "          \n",
        "        predicted = algorithm(train_set_X,train_set_Y, test_set_X,test_set_Y)\n",
        "        actual = [num for num in fold_Y]\n",
        "        accuracy = accuracy_metric(actual, predicted)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    return accuracies\n",
        "\n",
        "def naive_bayes(X,Y,test_X,test_Y):\n",
        "    dictionary=compute_counts(X,Y)\n",
        "    \n",
        "    neg_count,pos_count=compute_label_count(dictionary)#redundant simply use Y to get the counts later\n",
        "   \n",
        "    neg_prob=Y.count(0)/len(Y)#P(Y=0)\n",
        "    pos_prob=Y.count(1)/len(Y)#P(Y=1)\n",
        "    predictions=[]\n",
        "    for i in range(0,len(test_X)):\n",
        "        pred=predict(test_X[i],dictionary,neg_count,pos_count,neg_prob,pos_prob)\n",
        "        predictions.append(pred)\n",
        "    return predictions    \n",
        "\n",
        "#start from here       \n",
        "if __name__ == \"__main__\":\n",
        "    row=split_lines('dataset_NB.txt')#get a list of lists with sentence and class label in each child list\n",
        "    X=[]        \n",
        "    '''\n",
        "        X is a list of list of tokens like this:\n",
        "        [['This','is','token'],\n",
        "        ['Another','token']]\n",
        "        \n",
        "    '''\n",
        "    for i in range(0,len(row)):\n",
        "        tokens=tokenizer(row[i][0])#list of token strings\n",
        "        # Removing symbols        \n",
        "        X.append(tokens)\n",
        "    \n",
        "    Y=[ row[i][1] for i in range(0,len(row)) ]\n",
        "    \n",
        "    n_folds=7\n",
        "    accuarcies =evaluate_algorithm(X,Y,naive_bayes,n_folds)\n",
        "    print('Accuracies over each fold: %s' % accuarcies)\n",
        "    print('Average Accuracy: %.3f' % (sum(accuarcies)/float(len(accuarcies))))\n",
        "\n",
        "    '''\n",
        "        Y is list of class labels 0 or 1 like this:\n",
        "        [1,0,0,1,0,1,0]\n",
        "       \n",
        "    '''\n",
        "    #dictionary=compute_counts(X,Y)\n",
        "    \n",
        "    '''\n",
        "    dictonary contains all the words occuring in the text file and the count of occurences in -ve and +ve sentiments like this\n",
        "    \n",
        "    { '\n",
        "       'This': [0, 1], # each index contains -ve and +ve occurences respectively\n",
        "       'is': [1, 1],\n",
        "       'good.': [0, 1],\n",
        "       'It': [1, 0],\n",
        "       'BAD': [2, 0]\n",
        "    }\n",
        "    \n",
        "    '''\n",
        "    #print(type(dictonary['This'][0]))\n",
        "    #neg_count,pos_count=compute_label_count(dictionary) #gives total number of positive and negative samples in the dataset\n",
        "    \n",
        "    \n",
        "    #predict method takes a sentence and predicts the class it might belong to\n",
        "    \n",
        "    #print(dictonary)\n",
        "    #result=predict(['This', 'is', 'a' ,'test'],dictonary,neg_count,pos_count)#predict method takes a single sample and returns expected outcome\n",
        "    #print(\"Predicted Outcome: \",result)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracies over each fold: [76.76056338028168, 76.76056338028168, 78.16901408450704, 81.69014084507043, 81.69014084507043, 85.2112676056338, 76.76056338028168]\n",
            "Average Accuracy: 79.577\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}